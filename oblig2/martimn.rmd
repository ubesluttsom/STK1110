---
title: "`STK1110-h21:` Obligatorisk innlevering 2"
author: "Martin Mihle Nygaard (`martimn`)"
output:
  pdf_document:
    latex_engine: xelatex
    extra_dependencies: ["commath", "cancel", "lipsum"]

header-includes: |
    \DeclareMathOperator{\Var}{Var}
    \DeclareMathOperator{\E}{E}
---

# Oppgave 1 --- Bare blåbær

## Deloppgave (a) --- 95% konfidensintervall

Jeg lager et histogram over målingene, $X_1, X_2, … , X_n$, for å forsikre meg
om at de er sånn passe normalfordelt.

```{r}
anotocyan <- c(525, 587, 547, 558, 591, 531, 571, 551, 566, 622, 561, 502, 556, 565, 562)
hist(anotocyan, main = '')
```

Og det ser det ut som de er. $X_1, X_2, … , X_n$ kan da sees på som tilfeldige
uttrekninger fra en normalfordeling med forventningsverdi $μ$ og standardavvik
$σ$. Ettersom antall observasjoner $n$ er mindre enn tommelfingerreglen 40,
tar jeg utgangspunkt i $t$-fordelingen. Fra læreboka (Devore s. 403) bruker
jeg proposisjon (8.14),
$$
  \intoo{ \bar{x} - t_{α/2,n-1} · \frac s {\sqrt n},
          \bar{x} + t_{α/2,n-1} · \frac s {\sqrt n} }
$$
hvor $\bar{X}$ er snittet av observasjonene, $s$ standardavviket og $t_{α,n-1}$
ønsket andel $α$ av tetthetsfunksjonen til $t$-fordelingen med $n-1$
frihetsgrader. Jeg setter inn for disse og gjør beregningene i `R`.

```{r}
alpha <- 1 - 0.95
anotocyan.mean <- mean(anotocyan)
anotocyan.sd   <- sd(anotocyan)
anotocyan.n    <- length(anotocyan)
KI <- c(anotocyan.mean - qt(1-alpha/2, anotocyan.n-1) * anotocyan.sd / sqrt(anotocyan.n),
        anotocyan.mean + qt(1-alpha/2, anotocyan.n-1) * anotocyan.sd / sqrt(anotocyan.n))
```

Dette gir 95% konfidensintervallet (`r round(KI[1], 3)`, `r round(KI[2], 3)`).

## Deloppgave (b) --- Simulert $t$-fordeling konfidensintervall

```{r}
teller <- 0
for (i in 1:10000) {
  uttrekk      <- rnorm(15, mean = 558, sd = 30)     # trekk ut 15 observasjoner
  uttrekk.mean <- mean(uttrekk)                      # finn snittet av disse
  uttrekk.sd   <- sd(uttrekk)                        # finn standardavvik
  intervall    <- c(uttrekk.mean - qt(0.975, 15-1) * uttrekk.sd / sqrt(15),
                    uttrekk.mean + qt(0.975, 15-1) * uttrekk.sd / sqrt(15))
  if (intervall[1] <= 558 & 558 <= intervall[2]) {   # hvis 558 er innenfor KI
    teller <- teller + 1                             # ==> øk teller med én
  }
}
```

Dette gir `r teller` antall simulerte konfidensintervaller som inneholder 558.
Dette utgjør `r teller / 100`% av totalt antall simuleringer. Hvis koden min er
lusløs, er dette akkurat som intervallet forutså; 95%-konfidensintervall betyr
at verdien vi undersøker skal være innafor 95% av tiden, som er omtrent
tilfellet i disse simuleringene.

## Deloppgave (c) --- Simulert konfidensintervall for store utvalg

Gjør akkurat samme steg som forrige gang, bare med alternativt intervall, som
spesifisert i oppgaven.

```{r}
teller <- 0
for (i in 1:10000) {
  uttrekk      <- rnorm(15, mean = 558, sd = 30)     # trekk ut 15 observasjoner
  uttrekk.mean <- mean(uttrekk)                      # finn snittet av disse
  uttrekk.sd   <- sd(uttrekk)                        # finn standardavvik
  intervall    <- c(uttrekk.mean - 1.96 * uttrekk.sd / sqrt(15),
                    uttrekk.mean + 1.96 * uttrekk.sd / sqrt(15))
  if (intervall[1] <= 558 & 558 <= intervall[2]) {   # hvis 558 er innenfor KI
    teller <- teller + 1                             # => øk teller med én
  }
}
```

Dette gir (i en eksempelkjøring) `r teller` antall simulerte
konfidensintervaller som inneholder 558. Dette utgjør `r teller / 100`% av
totalt antall simuleringer. Altså, dette blir slett ikke et 95%
konfidensintervall; andelen innenfor intervallet blir for lavt. Dette er som
forventet, siden vi har så få observasjoner (15), som strider med betingelsen
«stort utvalg».

## Deloppgave (d) --- Konfidensintervall for $σ$

Jeg bruker formuleringen av konfidensintervall for varians og standardavvik fra
læreboka (Devore, s. 410).
```{=latex}
\begin{equation}
  \intoo{ \frac {(n - 1) s^2} {χ^2_{α/2,n-1}},
          \frac {(n - 1) s^2} {χ^2_{1-α/2,n-1}} }
  \label{int:chisqr}
\end{equation}
```
Hvor $χ^2_{α,v}$ er kvantilfunksjonen chi-kvadrat fordelingen. Jeg bruker så
`R` som i tidligere deloppgaver.

```{r}
teller <- 0
for (i in 1:10000) {
  uttrekk      <- rnorm(15, mean = 558, sd = 30)   # trekk ut 15 observasjoner
  uttrekk.var  <- var(uttrekk)                     # finn standardavvik
  intervall    <- sqrt(c((15-1) * uttrekk.var / qchisq(0.975, 15-1, lower.tail = TRUE),
                         (15-1) * uttrekk.var / qchisq(0.975, 15-1, lower.tail = FALSE)))
  if (intervall[1] <= 30 & 30 <= intervall[2]) {   # hvis 30 er innenfor KI
    teller <- teller + 1                           # ==> øk teller med én
  }
}
```
I en eksempelkjøring, får vi `r teller` intervaller som inneholder 30. Dette
utgjør en andel på `r teller/100`%. Som er svært nær forventningen på 95%.

## Deloppgave (e) --- Konfidensintervall for $μ$ med $t$-fordelt populasjon

```{r}
teller <- 0
for (i in 1:10000) {
  uttrekk   <- rt(15, 7)
  x         <- 558 + uttrekk * 30
  intervall <- c(mean(x) - qt(0.975, 15-1) * sd(x) / sqrt(15),
                 mean(x) + qt(0.975, 15-1) * sd(x) / sqrt(15))
  if (intervall[1] <= 558 & 558 <= intervall[2]) {   # hvis 30 er innenfor KI
    teller <- teller + 1                             # ==> øk teller med én
  }
}
```

I en eksempelkjøring, får vi `r teller` intervaller som inneholder 30. Dette
utgjør en andel på `r teller/100`%.

Øh, hvis oppgaven er tiltenkt å ta stilling til robusthet som beskrevet i denne
Wikipedia artikkelen[^robust], er jeg usikker. Jeg får jo samme resultat som i
deloppgave (b), men vet ikke om dette betyr at metoden er «robust» under en
eller annen streng definisjon.

[^robust]: \url{https://en.wikipedia.org/wiki/Robust_confidence_intervals}

## Deloppgave (f) --- Konfidensintervall for $σ$ med $t$-fordelt populasjon

```{r}
tilde_sigma <- sqrt(1.4) * 30
teller      <- 0
for (i in 1:10000) {
  uttrekk   <- rt(15, 7)
  z         <- 558 + uttrekk * tilde_sigma
  intervall <- sqrt(c((15-1) * var(z) / qchisq(0.975, 15-1, lower.tail = TRUE),
                      (15-1) * var(z) / qchisq(0.975, 15-1, lower.tail = FALSE)))
  if (intervall[1] <= tilde_sigma & tilde_sigma <= intervall[2]) {
    teller <- teller + 1
  }
}
```

I en eksempelkjøring, får vi `r teller` intervaller som inneholder
$\tilde{σ} = \sqrt{1.4}·σ = \sqrt{1.4}·30$. Dette utgjør en andel på
`r teller/100`%. Dette er mindre enn 95%, som var det jeg siktet på. Tror dette
kommer av at betingelsen om en normalfordelt populasjon for bruk av
\eqref{int:chisqr} er brutt; populasjonen er nå $t$-fordelt i stedet, og
tydeligvis ikke nærme nok normalfordeling.

# Oppgave 2 --- Hete kropper

## Deloppgave (a) --- Boksplott

```{r}
par(ps = 10) 
temp <- read.table("https://www.uio.no/studier/emner/matnat/math/STK1110/data/temp.txt",
                   header = TRUE)
boxplot(temp, col = c("red", "blue"))
```

Det ser ut som menn har en lavere kroppstemperatur enn kvinner i dette
datasettet. Men medianen er ikke ekstremt forskjellig.

## Deloppgave (b) --- Normalfordelingsplott

```{r}
par(mfrow = c(1,2), pty = "s", ps = 10)
qqnorm(temp$Menn, col = "red", xlab = "Menn", ylab = "", main = NULL)
qqnorm(temp$Kvinner, col = "blue", xlab = "Kvinner", ylab = "", main = NULL)
```

Det ser ut til at dataene sammenfaller ganske greit med normalfordeling,
ettersom datapunktene ligger omtrent på en rett linje. Det virker som
temperaturene målt på kvinner er noe mer kurvet, som kan tyde på en viss
skjevhet (dette ser man litt i boksplottet også).

## Deloppgave (c) --- Normalfordelte, små, utvalg med ukjent, lik, varians

La den stokastiske variabelen $X$ være kroppstemperaturen en tilfeldig kvinne
og $Y$ til en tilfeldig mann. Jeg antar at observasjonene $X_1, … , X_m$ og
$Y_1, … , Y_n$ er uavhengig identisk fordelt med henholdsvis forventning $μ_K$
og $μ_M$.

Jeg antar at variansene er like, altså $σ^2_K = σ^2_M = σ^2$, men
ukjente. Ettersom både $X$ og $Y$ er antatt normalfordelte, vil også
transformasjonen $\bar{X}-\bar{Y}$ også være normalfordelt med forventning
$μ_K - μ_M$. En estimator for $σ^2$ som tar høyde for forskjellig
utvalgstørrelse (altså at $m≠n$) er
\begin{equation}
  S^2_p = \frac {m-1} {m+n-2} S^2_K + \frac {n-1} {n+m-2} S^2_M \label{eq:var}
\end{equation}
hvor $S^2_{\{K,M\}}$ er den observerte variansen.

Jeg kan nå konstruere en ny stokastisk, standardisert, variabel $T$. Denne er
$t$-fordelt ettersom vi har for få observasjoner til å anta «stort» utvalg.
Altså,^[`TODO:` kjapt forklar hvor $\sqrt{\frac 1m + \frac1n}$ kommer fra.]
```{=latex}
\begin{equation}
  T = \frac { \del{\bar{X}-\bar{Y}} - \del{μ_K - μ_M} } { S_p \sqrt{\frac 1m + \frac1n} }
  \sim t_{m+n-2} \label{eq:T}
\end{equation}
```

### Hypotesetest

Jeg ønsker å undersøke om $μ_K ≠ μ_M$, eller ekvivalent $μ_K - μ_M ≠ 0$. Jeg
formulerer derfor nullhypotesen $H_0$ og alternativhypotesen $H_a$ som følger:

  * $H_0$: $μ_K - μ_M = Δ_0 = 0$
  * $H_a$: $μ_K - μ_M ≠ Δ_0 = 0$

Jeg bruker \eqref{eq:T} som testvariabel, hvor $μ_K - μ_M$ erstattes med $Δ_0$.
Dette fungerer ettersom denne $t$-fordelingen er sentrert rundt 0
(standardisert), og jeg ønsker å undersøke om differansen $Δ_0$ er langt nok
unna 0, gitt et visst standardavvik. Jeg ønsker å være 95% sikker, eller
«konfident», om du vil. Derfor formuleres forkastingsbettingelsen slik:
$$
  H_0 \text{ forkastes dersom } \left.
  \begin{cases}
    t ≤ t_{α/2,m+n-2} \\
    t ≥ t_{1-α/2,m+n-2}
  \end{cases}\right\}
  \text{ hvor } t = \frac {\del{\bar{X}-\bar{Y}} - Δ_0} {S_p {\sqrt{\frac 1m + \frac1n}}}
  \text{ og } α = 1 - 95\%.
$$

### Konfidensintervall

Jeg ønsker et intervall som det er $1-α$ sannsynlighet for at $T$ befinner seg
i. Øvre og nedre skranke for dette intervallet blir $±t_{α/2,m+n-2}$. Jeg
manipulerer dette intervallet til heller å beskrive $\del{μ_K-μ_M}$:
```{=latex}
\begin{align*}
  1-α &= \text{P}\del{ t_{α/2,m+n-2}                                                             ≤ \frac { \del{\bar{X}-\bar{Y}} - \del{μ_K - μ_M} } { S_p \sqrt{\frac 1m + \frac1n}} ≤ t_{1-α/2,m+n-2} } \\
      &= \text{P}\del{ t_{α/2,m+n-2} S_p \sqrt{\frac 1m + \frac1n}                               ≤ { \del{\bar{X}-\bar{Y}} - \del{μ_K - μ_M} }                                        ≤ t_{1-α/2,m+n-2} {S_p} {\sqrt{\frac 1m + \frac1n}} } \\
      &= \text{P}\del{ - \del{\bar{X}-\bar{Y}} + t_{α/2,m+n-2} S_p {\sqrt{\frac 1m + \frac1n}}   ≤ - μ_K - μ_M                                                                        ≤ - \del{\bar{X}-\bar{Y}} + t_{1-α/2,m+n-2} S_p \sqrt{\frac 1m + \frac1n} } \\
      &= \text{P}\del{   \del{\bar{X}-\bar{Y}} - t_{α/2,m+n-2} S_p {\sqrt{\frac 1m + \frac1n}}   ≥   μ_K - μ_M                                                                        ≥   \del{\bar{X}-\bar{Y}} - t_{1-α/2,m+n-2} S_p \sqrt{\frac 1m + \frac1n} } \\
      &= \text{P}\del{   \del{\bar{X}-\bar{Y}} - t_{1-α/2,m+n-2} S_p {\sqrt{\frac 1m + \frac1n}} ≤   μ_K - μ_M                                                                        ≤   \del{\bar{X}-\bar{Y}} - t_{α/2,m+n-2} S_p \sqrt{\frac 1m + \frac1n} }
\end{align*}
```
Siste linje gir meg formuleringen av konfidensintervallet for differansen mellom
forventningene til de to variablene $X$ og $Y$:
$$
  \intoo{
    \del{\bar{x}-\bar{y}} - t_{1-α/2,m+n-2} · s_p {\sqrt{\frac 1m + \frac1n}},
    \del{\bar{x}-\bar{y}} - t_{α/2,m+n-2} · s_p {\sqrt{\frac 1m + \frac1n}}
  }
$$

### *P*-verdi

```{=latex}
\begin{align*}
  P\text{-verdi} &= P\del{ -t ≥ T ≥ t \ | \ μ_K - μ_M = 0 } \\
                 &≈ \text{ område under $t$-kurven før $-t$ og etter $t$} \\
                 &= 1 - \int_{-t}^{t}{t_{m+n-2}} \\
                 &= 2 · \del{ 1 - F_{m+n-2}(t)}
\end{align*}
```
Hvor $F_{v}$ er den kumulative fordelingsfunksjonen for $t$-fordelingen med $v$
frihetsgrader. Her utnytter jeg at $t$-fordelingen er symmetrisk, som er
hvorfor jeg ganger med to (for nedre og øvre hale).

### Sjekk i `R`

```{r}
# Hypotesetest
alpha    <- 1-0.95
Δ_0      <- 0
x_strek  <- mean(temp$Kvinner)
y_strek  <- mean(temp$Menn)
m        <- length(temp$Kvinner)
n        <- length(temp$Menn)
S_p      <- sqrt(((m-1)/(m+n-2)) * var(temp$Kvinner) + ((n-1)/(n+m-2)) * var(temp$Menn))
t        <- ((x_strek-y_strek) - Δ_0) / (S_p * sqrt(1/m + 1/n))
skranker <- c(qt(alpha/2, m+n-2), qt(1-alpha/2, m+n-2))

# Konfidensintervall
KI <- c((x_strek-y_strek) - qt(1-alpha/2, m+n-2) * S_p * sqrt(1/m + 1/n),
        (x_strek-y_strek) - qt(alpha/2, m+n-2) * S_p * sqrt(1/m + 1/n))

# P-verdi
P_verdi <- 2*(1-pt(t, m+n-2))
```

Dette gir $t =`r t`$, som ligger utenfor intervallet $\intoo{`r skranker[1]`,
`r skranker[2]`}$. $H_0$ bør derfor forkastes. $P$-verdien er i samsvar med
denne konklusjonen, siden $P$-verdi $=`r P_verdi`<α=0.05$. Konfidensintervallet
blir $\intoo{`r KI[1]`, `r KI[2]`}$.

Jeg får god overensstemmelse med `R`s innebygde $t$-test.
```{r}
t.test(temp$Kvinner, temp$Menn)
```

## Deloppgave (d) --- Ulik varians

I tilfellet med forskjellig varians må jeg justere litt på \eqref{eq:T}.^[Her
er jeg lite stødig, og innrømmer ærlig at jeg regurgiterer forelesningsfoilene.]
```{=latex}
\begin{align*}
  T &= \frac { \del{\bar{X}-\bar{Y}} - \del{μ_K - μ_M} } {\sqrt{\frac {S^2_K}m + \frac{S^2_M}n} } \\
    &= \frac { \del{\bar{X}-\bar{Y}} - \del{μ_K - μ_M} } {\sqrt{\frac {S^2_K}m + \frac{S^2_M}n} } · \frac {\del{{\sqrt{σ^2_K/m + σ^2_M/n}}}^{-1}} {\del{\sqrt{σ^2_K/m + σ^2_M/n}}^{-1}} \\
    &= \frac { \del{\bar{X}-\bar{Y}} - \del{μ_K - μ_M} } {\sqrt{σ^2_K/m + σ^2_M/n} } · \frac {\del{\sqrt{\frac {S^2_K}m + \frac{S^2_M}n}}^{-1}} {\del{\sqrt{σ^2_K/m + σ^2_M/n}}^{-1}} \\
    &= \frac { \del{\bar{X}-\bar{Y}} - \del{μ_K - μ_M} } {\sqrt{σ^2_K/m + σ^2_M/n} } · \del{\sqrt{\frac {\frac {S^2_K}m + \frac{S^2_M}n} {σ^2_K/m + σ^2_M/n} }}^{-1} \\
    &= Z · \sbr{ \sqrt { \frac U ν } }^{-1}
       \text{, hvor } Z=\frac{\del{\bar{X}-\bar{Y}}-\del{μ_K-μ_M}}{\sqrt{σ^2_K/m+σ^2_M/n}} ∼ N(0,1)
       \text{ og } \frac Uν=\frac{\frac{S^2_K}m+\frac{S^2_M}n}{σ^2_K/m+σ^2_M/n}
\end{align*}
```
$U$ kan tilnærmes med $χ^2_ν$ fordelingen. Da brukes en justert $v$, som tilnærmes
med de observerte variansene $S^2_K$ og $S^2_M$ slik:
$$
  ν = \frac {σ^2_K/m + σ^2_M/n} { \del{\frac{σ^2_K}m}^2 / \del{m-1} + \del{\frac{σ^2_M}n}^2 / \del{n-1}}
    ≈ \frac {S^2_K/m + S^2_M/n} { \del{\frac{S^2_K}m}^2 / \del{m-1} + \del{\frac{S^2_M}n}^2 / \del{n-1}}
$$

Denne $ν$-en brukes tilnærme riktig $t$-fordeling:
$$
  T = \frac{\del{\bar{X}-\bar{Y}}-\del{μ_K-μ_M}}{\sqrt{S^2_K/m+S^2_M/n}} ∼ t_ν
$$

### Hypotesetest

Som i forrige deloppgave, men forkastingsbettingelsen blir
$$
  H_0 \text{ forkastes dersom } \left.
  \begin{cases}
    t ≤ t_{α/2,ν} \\
    t ≥ t_{1-α/2,ν}
  \end{cases}\right\}
  \text{ hvor } t = \frac{\del{\bar{X}-\bar{Y}}-Δ_0}{\sqrt{S^2_K/m+S^2_M/n}}
  \text{ og } α = 1 - 95\%.
$$

### Konfidensintervall

Utledningen er analog til forrige oppgave. Konfidensintervallet blir
$$
  \intoo{
    \del{\bar{x}-\bar{y}} - t_{1-α/2,ν} · {\sqrt{s^2_k/m+s^2_m/n}},
    \del{\bar{x}-\bar{y}} - t_{α/2,ν}   · {\sqrt{s^2_k/m+s^2_m/n}}
  }
$$

### *P*-verdi

Igjen, som i forrige oppgave, men med $ν$ innsatt for $m+n-2$.
```{=latex}
\begin{align*}
  P\text{-verdi} &= P\del{ -t ≥ T ≥ t \ | \ μ_K - μ_M = 0 } \\
                 &≈ \text{ område under $t$-kurven før $-t$ og etter $t$} \\
                 &= 1 - \int_{-t}^{t}{t_{ν}} \\
                 &= 2 · \del{ 1 - F_{ν}(t)}
\end{align*}
```

### Utregning i `R`

```{r}
# Hypotesetest
v        <- ( (var(temp$Kvinner)/m + var(temp$Menn)/n)
            / ((var(temp$Kvinner)/m)^2/(m-1) + (var(temp$Menn)/n)^2/(n-1)))
t        <- ( ((x_strek-y_strek) - Δ_0)
            / sqrt(var(temp$Kvinner)/m + var(temp$Menn)/n))
skranker <- c(qt(alpha/2, v), qt(1-alpha/2, v))

# Konfidensintervall
KI <- c((x_strek-y_strek)-qt(1-alpha/2, v) * sqrt(var(temp$Kvinner)/m+var(temp$Menn)/n),
        (x_strek-y_strek)-qt(alpha/2, v)   * sqrt(var(temp$Kvinner)/m+var(temp$Menn)/n))

# P-verdi
P_verdi <- 2*(1-pt(t, v))
```

Dette gir $t =`r t`$, som ligger utenfor intervallet $\intoo{`r skranker[1]`,
`r skranker[2]`}$. $H_0$ bør derfor fortsatt forkastes (om jeg ikke har regna
feil). $P$-verdien er fortsatt i samsvar: $P$-verdi $=`r P_verdi`<α=0.05$.
Konfidensintervallet blir $\intoo{`r KI[1]`, `r KI[2]`}$.

Det virker som antagelsen om ulik varians drastisk styrker $H_a$. Litt
spekulasjon, men fra plottet i deloppgave (a) kan vi se at observasjonene av
kvinnenes temperatur har noe mindre varians; hvis denne variansen hadde vært
mer jevnstor med mennenes (altså antagelse om lik varians), ville de to
fordelingene overlappet mer, og desto mer observasjonene overlapper, jo
vanskeligere er det å fastslå med sikkerhet at de er forskjellige? Derfor vil
sikkerheten øke (og $P$-verdien minske).

## Deloppgave (e) --- F-test

Følger metoden beskrevet i seksjon 10.5 (Devore s. 527). Jeg formulerer
følgende hypoteser om variansen:
- $H₀$: $σ_K² = σ_M²$
- $Hₐ$: $σ_K² ≠ σ_M²$
Som teststatistikk bruker jeg forholdet $f = s_K² / s_M²$, som har en
F-fordeling med parametre $v₁=m-1$ og $v₂=n-1$. Forkastingsbetingelsene blir
$$
  H_0 \text{ forkastes dersom } \left.
  \begin{cases}
    f ≤ F_{  α/2,m-1,n-1} \\
    f ≥ F_{1-α/2,m-1,n-1}
  \end{cases}\!\!\!\right\}
  \text{ hvor } f = \frac{s_K²}{s_M²}
  \text{ og } α = 1 - 95\%.
$$

```{r}
m <- length(temp$Kvinner)
n <- length(temp$Menn)
f <- var(temp$Kvinner)/var(temp$Menn)
f.forkast <- c(qf(  alpha/2, m-1, n-1),
               qf(1-alpha/2, m-1, n-1))
f.konfint <- c(f*qf(alpha/2, m-1, n-1),
               f/qf(alpha/2, m-1, n-1))
```
Basert på `R` koden over, ser det ut som $f ≈ `r round(f, 3)`$ *ikke* ligger i
forkastingsområdet til $H₀$, altså innenfor intervallet
$\intoo{`r round(f.forkast[1],3)`, `r round(f.forkast[2],3)`}$, som impliserer
at den alternative hypotesen bør forkastes. Et 95% konfidensintervall for $f$
blir $\intoo{`r round(f.konfint[1],3)`, `r round(f.konfint[2],3)`}$. Jeg får
god overensstemmelse med den innebygde testen:

```{r}
var.test(temp$Kvinner, temp$Menn)
```

## Deloppgave (f) --- Prediksjonsintervall

```{=latex}
Med utgangspunkt i normalfordeling på både $X$ og $Y$, vet jeg at
forventningsrette estimatorer for disse er snittet, henholdsvis $\bar X$ og
$\bar Y$. Videre, vet jeg også at observasjonene er uavhengig identisk fordelt,
derfor er det rimelig å anta at neste observasjon har samme forventning som de
foregående. Med disse antagelsene blir forventningen da
$$
  \E(X₁₁-Y₁₁) = \E(X₁₁) - \E(Y₁₁) = \E(X) - \E(Y) = \bar X - \bar Y.
$$

Jeg prøver å finne forventningen og variansen til uttrykket $X₁₁-Y₁₁-(\bar
X-\bar Y)$:
\begin{align*}
  \E\sbr{X₁₁-Y₁₁-(\bar X-\bar Y)}
    &= \E\sbr{X₁₁} - \E\sbr{Y₁₁} - \E\sbr{\bar X} + \E\sbr{\bar Y} \\
    &= \bar X - \bar Y - \bar X + \bar Y = 0 \\
  \Var\sbr{X₁₁-Y₁₁-(\bar X-\bar Y)}
    &= \Var\sbr{X₁₁} + \Var\sbr{Y₁₁} + \Var\sbr{\bar X} + \Var\sbr{\bar Y} \\
    &= σ_K² + σ_M² + \frac{σ_K²}m + \frac{σ_M²}n
\end{align*}
Videre, hvis jeg antar at variansene til $X$ og $Y$ er like --- som foreslått i
forrige deloppgave --- kan jeg bruke det vektede snittet til de observerte
variansene $S²_p$ fra \eqref{eq:var}.
\begin{align*}
  σ_K² + σ_M² + \frac{σ_K²}m + \frac{σ_M²}n
    = S²_p + S²_p + \frac{S²_p}m + \frac{S²_p}n
    = S²_p \del { 2 + \frac1m + \frac1n }
\end{align*}

Hvis variansen er kjent, blir fordelingen til uttrykket $X₁₁-Y₁₁-(\bar X-\bar
Y)$ normalfordelt ettersom dette er en lineærkombinasjon av antatt
normalfordelte stokastiske variable. Hvis variansen er ukjent er det snakk om
T-fordeling\footnote{Jeg antar med $m+n-2$ frihetsgrader, men det er jeg
oppriktig talt usikker på.}. Så --- jeg tror --- vi kan konstruere en
stokastisk variabel
$$
  T₁₁ = \frac { X₁₁-Y₁₁-(\bar X-\bar Y) - 0 } { S_p \sqrt { 2 + \frac1m + \frac1n } } ∼ t_{m+n-2}.
$$
Denne $T₁₁$ kan jeg manipulere for å finne et prediksjonsintervall, akkurat som
tidligere med konfidensintervall.
\begin{align*}
  1-α
  &= \mathrm P\sbr{ t_{α/2,m+n-2} < T₁₁ < t_{1-α/2,m+n-2} } \\
  &= \mathrm P\sbr{ t_{α/2,m+n-2} < \frac {X₁₁-Y₁₁-(\bar X-\bar Y) - 0} {S_p \sqrt{2 + \frac1m + \frac1n}} < t_{1-α/2,m+n-2} } \\
  &= \mathrm P\sbr{ \bar X-\bar Y + t_{α/2,m+n-2} · S_p \sqrt{2 + \tfrac1m + \tfrac1n} < X₁₁-Y₁₁ < \bar X-\bar Y + t_{1-α/2,m+n-2} · S_p \sqrt{2 + \tfrac1m + \tfrac1n} }
\end{align*}
Setter jeg inn de observerte snittene, $m$, $n$, og $α$, får jeg følgende 95\%
prediksjonsintervall for $X₁₁-Y₁₁$:
$$
  \intoo{ \bar x-\bar y + t_{.025,18} · s_p \sqrt{2 + \tfrac2{10}},\ \bar x-\bar y + t_{.975,18} · s_p \sqrt{2 + \tfrac2{10}} }
$$
```
Dette er altså et intervall vi skal være 95\% sikre på at differansen mellom
kroppstemperaturen til neste observerte kvinne og mann faller innenfor. Dette
i motsetning til konfidensintervallet fra deloppgave (c), hvor vi ønsket å
finne et intervall for den forventede gjennomsnittforskjellen.

Dette intervallet er betydelig bredere enn konfidensintervallet for $μ₁-μ₂$.
Dette kommer av at usikkerheten rundt $μ₁-μ₂$ minsker med mengden data; mens
$X₁₁-Y₁₁$ vil \emph{alltid} ha en usikkerhet proporsjonal med den faktiske
variansen i dataene (reflektert i det konstante leddet under rottegnet).

# Oppgave 3 --- Fedre i tidsklemma

## Deloppgave (a) --- Hypotesetest, p-verdi

Dette er et «stort» utvalg. La $p_M$ og $p_F$ være henholdsvis andelen mødre og
fedre i «tidsklemma», og $\hat p_{\{M,F\}}$ er de observerte andelene. La $\hat p$
være et vektet gjennomsnitt av de to populasjonsandelene, altså
$$
  \hat p = \frac m {m+n} \hat p_M + \frac n {n+m} \hat p_F.
$$
Hvor $m$ og $n$ er antall mødre og fedre spurt, henholdsvis (begge er 3000 i
denne undersøkelsen). Jeg formulerer følgende hypoteser:

  * $H_0$: $p_M - p_F = 0$
  * $H_a$: $p_M - p_F ≠ 0$

Og setter forkastingsbettingelsen
$$
  H_0 \text{ forkastes dersom } \left.
  \begin{cases}
    z ≤ z_{α/2} \\
    z ≥ z_{1-α/2}
  \end{cases}\right\}
  \text{ hvor } z = \frac{\hat p_M - \hat p_F}{\sqrt{{\hat p (1-\hat p) \del{1/m+1/n}}}}
  \text{ og } α = 1 - 95\%.
$$

P-verdien er gitt ved $2·\del{1-Φ(|z|)}$.

Jeg bruker `R` til å regne ut de faktiske verdiene.
```{r}
pM <- 441
pF <- 486
m <- 3000
n <- 3000
pM_hatt <- pM/m
pF_hatt <- pF/n
p_hatt  <- (m*pM_hatt)/(m+n) + (n*pF_hatt)/(m+n)
z <- (pM_hatt - pF_hatt) / sqrt(p_hatt*(1/m+1/n))
forkast <- c(qnorm(alpha/2), qnorm(1-alpha/2))
p_verdi <- 2*(1-pnorm(abs(z)))
```
Test verdien $z = `r z`$ ligger innenfor skrankene `r forkast[1]` og
`r forkast[2]`. $H_0$ beholdes, og $H_a$ forkastes. P-verdien er
`r p_verdi`, som ikke er mindre enn signifikansnivået på 5%.

Altså, forskjellen mellom mødre og fedre er ikke signifikant.

## Deloppgave (b) --- Sjekk i `R`

```{r}
prop.test(c(441, 486), c(3000, 3000), correct = FALSE)
```
Jeg vil si at forskjellen fortsatt *ikke* er signifikant. Men jeg får
forskjellig p-verdi. Fra p-verdien her ser man at et slikt resultat vil
forekomme 10.8% av tiden, hvis det ikke er noen forskjell mellom mødre
og fedre (altså om $H_0$ er sann).
